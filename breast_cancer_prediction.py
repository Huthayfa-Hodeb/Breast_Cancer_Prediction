# -*- coding: utf-8 -*-
"""Breast_Cancer_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14n9XIe-5H89yo2GE3MWbuc-JEscY2eYX

# Install CatBoost Library
"""

pip install catboost

"""# Importing the libraries"""

import pandas as pd
import numpy as np
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
from sklearn.metrics import  f1_score, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV

"""# Importing the dataset"""

dataset = pd.read_csv("Data.csv")

"""# Taking a look in the data set"""

dataset.head()

dataset.dtypes

dataset.shape

"""# Take a quick look at the Target column"""

dataset['Class'].value_counts()

"""# Taking care of missing data"""

dataset.isnull().sum()[dataset.isnull().sum() > 0]

"""# Encoding categorical data

Label Encoding
"""

dataset['Class'] = LabelEncoder().fit_transform(dataset['Class'])

dataset['Class'].unique()

"""# Create X for features and y for target"""

X = dataset.iloc[:, 1:-1].values
y = dataset.iloc[:, -1].values

"""# Splitting the dataset into the Training set and Test set"""

X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.2, random_state = 0)

"""# Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

"""# Building model"""

results = []

# XGBoost :
classifier_xgb = XGBClassifier()

classifier_xgb.fit(X_train, y_train)

y_pred_xgb = classifier_xgb.predict(X_test)

results.append({
        'Model Name':'XGBoost',
        'Accuracy ': accuracy_score(y_pred_xgb, y_test)*100,
        'F1_score': f1_score(y_pred_xgb, y_test)*100 })

# CatBoost :
classifier_cb = CatBoostClassifier(verbose=False)

classifier_cb.fit(X_train, y_train)

y_pred_cb = classifier_cb.predict(X_test)

results.append({
        'Model Name':'CatBoost',
        'Accuracy ': accuracy_score(y_pred_cb, y_test)*100,
        'F1_score': f1_score(y_pred_cb, y_test)*100 })

df_report = pd.DataFrame(results)
styled_df = df_report.style.background_gradient(cmap='Blues')
styled_df

"""## Applying k-Fold Cross Validation"""

accuracies_catboost = cross_val_score(estimator = classifier_cb, X = X_train, y = y_train, cv = 10)
accuracies_xgboost = cross_val_score(estimator = classifier_xgb, X = X_train, y = y_train, cv = 10)

results = {
    'Model': ['CatBoost', 'XgBoost'],
    'Accuracy': [accuracies_catboost.mean()*100, accuracies_xgboost.mean()*100],
    'Standard Deviation': [accuracies_catboost.std()*100, accuracies_xgboost.std()*100]
}

df_report2 = pd.DataFrame(results)
styled_df = df_report2.style.background_gradient(cmap='Blues')
styled_df

"""# Applying Grid Search in XgBoost to find the best parameters"""

parameters = [{
    'max_depth': [3, 5, 7, 9, 11],
    'learning_rate': [0.1, 0.01, 0.001, 0.0001],
    'n_estimators': [100, 500, 1000, 1500, 2000]
    }]

grid_search = GridSearchCV(estimator = classifier_xgb, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)
grid_search.fit(X_train, y_train)
best_accuracy = grid_search.best_score_
best_parameters = grid_search.best_params_
print("Best Accuracy: {:.2f} %".format(best_accuracy*100))
print("Best_Parameters: ", best_parameters)

"""# Making single predict"""

predict = grid_search.predict([[5,4,4,5,7,10,3,2,1]])
if predict == 0 :
  print('The tumor is benign')
else:
  print("The tumor is malignant")